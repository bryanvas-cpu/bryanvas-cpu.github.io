---
title: "Hexapod"
description: Design, Implementation, Simulation, Testing
date: 2024-11-24
categories: [Simulation, Robotics, Hexapod]
tags: [robotics, simulation, hexapod]
author: "Bryan Vas"
image: assets/images/Hexapod/Hexapod_cad.PNG # Feature image for the post
---

# Hexapod: Design, Implementation, and Testing

My current main focus has been on creating, a highly versatile, robust, and feature rich hexapod. 
Features that it is meant to have include, a complete ROS2 based Controller, Upgradable design, Cameras for perception, Feet contact sensors, Reinforcement learning based control for walking on rough terrain, Various walking Gaits, Various motion filter modes.

## ROS2 Based Controller

Latest update: The ROS2 based controller, here I am using a PS4 controller to give commands.

### Simulation in Gazebo Simulator (Classical Control):

<div style="position: relative; width: 100%; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/OUmJqA5kmGM?si=adebjjhlsCn0wbzt&t=1" 
    frameborder="0" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
    allowfullscreen 
    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
</div>

### Overview

This shows the classical style hexapod controller, wherein, it follows:
- x_translation, y_translation, and Z_height, of hull.
- Linear (x,y) velocity of body.
- {Roll, Pitch}(Closed Loop Control) and {Yaw}(Open Loop) of hull. 
- Tripod, Ripple, and Amble gaits.
- Motion filters / Modes

## Reinforcement Learning in Isaac Gym

<div style="display: flex; justify-content: space-between; gap: 10px; flex-wrap: wrap;">
  <!-- First YouTube Short Video + Text -->
  <div style="flex: 1; max-width: 48%; text-align: center;">
    <div style="position: relative; padding-bottom: 177.78%; height: 0; overflow: hidden;">
      <iframe src="https://www.youtube.com/embed/-GyyXanEjBE?playsinline=1&mute=1" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
        allowfullscreen 
        style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
    </div>
    <p style="font-size: 16px; margin-top: 10px;">It learned to Walk</p>
  </div>

  <!-- Second YouTube Short Video + Text -->
  <div style="flex: 1; max-width: 48%; text-align: center;">
    <div style="position: relative; padding-bottom: 177.78%; height: 0; overflow: hidden;">
      <iframe src="https://www.youtube.com/embed/ujN2bUsZ3eY" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
        allowfullscreen 
        style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
    </div>
    <p style="font-size: 16px; margin-top: 10px;">Unexpected Interesting Stuff</p>
  </div>
</div>

<div style="flex: 1; max-width: 100%; text-align: center;">
  <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
    <iframe src="https://www.youtube.com/embed/t7yD85Wf9wE" 
      frameborder="0" 
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
      allowfullscreen 
      style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
  </div>
  <p style="font-size: 16px; margin-top: 10px;">Attempted camera based Learning (Not emough V-RAM on my laptop)</p>
</div>





### Overview

The goal is to train a model that adapts the hexapod's leg movements to maintain a stable hull while following velocity commands.

- The first video demonstrates the hexapod learning to follow basic linear and angular velocity commands.
- The second video is amusing.
- The third video showcases the use of camera input from each environment's hexapod, highlighting the potential to incorporate camera data during training.

## Technical Details

### Hardware
- **Hexapod (In development):** Custom-3D-Printed parts. 30Kg-cm Serial-bus-servos, Aluminum(2mm), Cameras. 
- **Sensors:** Contact sensors, 3-axis-Inclination, 3-axis-Acceleration.
- **Controller:** Raspberry-pi, Esp32-based Servo Driver.

### Software
- **Programming Language:** Embedded C, Python, C++.
- **Autonomy:** Wireless Teleoperation, Wired teleoperation, Camera guided Motion.

## Gallery

<!-- <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px;">
  <div>
    <img src="assets/images/UMV/UMV_internal.jpeg" alt="Rover Prototype" style="width: 100%;">
    <p style="text-align: center;">Figure 1: Rover prototype.</p>
  </div>
  <div>
    <img src="assets/images/UMV/umv_transmitter.jpeg" alt="Remote Control" style="width: 100%;">
    <p style="text-align: center;">Figure 2: Remote Control.</p>
  </div>
  <div>
    <img src="assets/images/UMV/Hostgator_data_example.png" alt="Stored Data" style="width: 100%;">
    <p style="text-align: center;">Figure 3: Stored Data.</p>
  </div>
  <div>
    <img src="assets/images/UMV/umv_live_page.jpeg" alt="Live Data" style="width: 100%;">
    <p style="text-align: center;">Figure 4: Live Data.</p>
  </div>
</div> -->


## Source Code

The complete codebase and documentation are available on [GitHub](https://github.com/bryanvas-cpu/Isaac_gym).

## Acknowledgments

Software: me, Hardware was funded by, IIT Dhanbad.

## Whatâ€™s Next?

A lot of cool stuff.
- Reinforcement Learning
- Building the Hardware and testing
- Improving the code structure
- Publishing the Controller
